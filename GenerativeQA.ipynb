{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90692f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import hashlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1747841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_path = \"./data/DuReaderQG/train.json\"\n",
    "    valid_path = \"./data/DuReaderQG/dev.json\"\n",
    "    # model_path = \"./model\"\n",
    "    model_checkpoint = 'langboat/mengzi-t5-base'\n",
    "    save_dir = \"./best_models\"\n",
    "    max_source_length = 1024\n",
    "    max_target_length = 128\n",
    "    batch_size = 4\n",
    "    accum_steps = 4\n",
    "    epochs = 30\n",
    "    val_samples_per_epoch = 1\n",
    "    seed = 42\n",
    "    valid_shuffle = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0a8d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 保证了所有 PyTorch 随机数（如 dropout、权重初始化）都能被固定，确保实验可复现。\n",
    "torch.manual_seed(Config.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ================== 数据加载 ==================\n",
    "def load_train_data(path):\n",
    "    \"\"\"加载训练数据（保持原始格式）\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "def load_valid_data(path):\n",
    "    \"\"\"加载验证数据（合并相同context+question）\"\"\"\n",
    "    grouped = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                sample = json.loads(line)\n",
    "                key = hashlib.md5(\n",
    "                    (sample[\"context\"] + sample[\"question\"]).encode()\n",
    "                ).hexdigest()\n",
    "                if key not in grouped:\n",
    "                    grouped[key] = {\n",
    "                        \"context\": sample[\"context\"],\n",
    "                        \"question\": sample[\"question\"],\n",
    "                        \"answers\": [],\n",
    "                        \"ids\": []\n",
    "                    }\n",
    "                grouped[key][\"answers\"].append(sample[\"answer\"])\n",
    "                grouped[key][\"ids\"].append(sample[\"id\"])\n",
    "    return list(grouped.values()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d158dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 数据加载检查 ===\n",
      "训练集样本数: 14520\n",
      "验证集样本数: 700 (合并后)\n"
     ]
    }
   ],
   "source": [
    "# 数据检查点\n",
    "print(\"\\n=== 数据加载检查 ===\")\n",
    "train_data = load_train_data(Config.train_path)\n",
    "valid_data = load_valid_data(Config.valid_path)\n",
    "print(f\"训练集样本数: {len(train_data)}\")\n",
    "print(f\"验证集样本数: {len(valid_data)} (合并后)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d23967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'context': '第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。',\n",
       "  'answer': '第35集',\n",
       "  'question': '仙剑奇侠传3第几集上天界',\n",
       "  'id': 0},\n",
       " {'context': '年基准利率4.35%。 从实际看,贷款的基本条件是: 一是中国大陆居民,年龄在60岁以下; 二是有稳定的住址和工作或经营地点; 三是有稳定的收入来源; 四是无不良信用记录,贷款用途不能作为炒股,赌博等行为; 五是具有完全民事行为能力。',\n",
       "  'question': '2017年银行贷款基准利率',\n",
       "  'answers': ['年基准利率4.35%', '4.35%'],\n",
       "  'ids': [0, 1]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], valid_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd17b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, is_train=True):\n",
    "        self.data = data\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        if self.is_train:\n",
    "            return {\n",
    "                \"context\": item[\"context\"],\n",
    "                \"question\": item[\"question\"],\n",
    "                \"answer\": item[\"answer\"],\n",
    "                \"id\": item[\"id\"]\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"context\": item[\"context\"],\n",
    "                \"question\": item[\"question\"],\n",
    "                \"answers\": item[\"answers\"],\n",
    "                \"id\": item[\"ids\"][0]\n",
    "            }\n",
    "\n",
    "train_dataset = QADataset(train_data, is_train=True)\n",
    "valid_dataset = QADataset(valid_data, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20f88a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'context': '第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。',\n",
       "  'question': '仙剑奇侠传3第几集上天界',\n",
       "  'answer': '第35集',\n",
       "  'id': 0},\n",
       " {'context': '年基准利率4.35%。 从实际看,贷款的基本条件是: 一是中国大陆居民,年龄在60岁以下; 二是有稳定的住址和工作或经营地点; 三是有稳定的收入来源; 四是无不良信用记录,贷款用途不能作为炒股,赌博等行为; 五是具有完全民事行为能力。',\n",
       "  'question': '2017年银行贷款基准利率',\n",
       "  'answers': ['年基准利率4.35%', '4.35%'],\n",
       "  'id': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0], valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd1316cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 把验证集按轮次（epoch）均匀地拆分成多份，以便在每个 epoch 只评估其中一部分样本，从而减少一次评估的开销或实现跨 epoch 的完整覆盖。\"\"\"\n",
    "class ValidChunker:\n",
    "    def __init__(self, dataset, total_epochs):\n",
    "        self.dataset = dataset\n",
    "        self.total_samples = len(dataset)\n",
    "        self.total_epochs = total_epochs\n",
    "        self.samples_per_epoch = self.total_samples // self.total_epochs\n",
    "        \n",
    "        self.indices = torch.arange(self.total_samples).tolist()\n",
    "        if Config.valid_shuffle:\n",
    "            random.shuffle(self.indices)\n",
    "        \n",
    "        # 处理不能整除的情况\n",
    "        if self.total_samples % self.total_epochs != 0:\n",
    "            pad = self.total_epochs - (self.total_samples % self.total_epochs)\n",
    "            self.indices += self.indices[:pad]\n",
    "            self.total_samples += pad\n",
    "\n",
    "    def get_chunk_indices(self, epoch):\n",
    "        start = epoch * self.samples_per_epoch\n",
    "        end = start + self.samples_per_epoch\n",
    "        return self.indices[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58171b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "valid_chunker = ValidChunker(valid_dataset, Config.epochs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config.model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab216bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collate(batch_data):\n",
    "    batch_inputs = [f\"question: {x['question']} context: {x['context']}\" for x in batch_data]\n",
    "    batch_targets = [x[\"answer\"] for x in batch_data]\n",
    "    \n",
    "    sources = tokenizer(\n",
    "        batch_inputs,\n",
    "        max_length=Config.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        batch_targets,\n",
    "        max_length=Config.max_target_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "    \n",
    "    targets[targets == tokenizer.pad_token_id] = -100\n",
    "    return {\n",
    "        \"input_ids\": sources.input_ids,\n",
    "        \"attention_mask\": sources.attention_mask,\n",
    "        \"labels\": targets\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da4f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_collate(batch):\n",
    "    batch_inputs = [f\"question: {x['question']} context: {x['context']}\" for x in batch]\n",
    "    processed = tokenizer(\n",
    "        batch_inputs,\n",
    "        max_length=Config.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": processed.input_ids,\n",
    "        \"attention_mask\": processed.attention_mask,\n",
    "        \"contexts\": [x[\"context\"] for x in batch],\n",
    "        \"questions\": [x[\"question\"] for x in batch],\n",
    "        \"answers\": [x[\"answers\"] for x in batch],\n",
    "        \"ids\": [x[\"id\"] for x in batch]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b39eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_collate(batch):\n",
    "    \"\"\"专注于前向推理和评估所需的所有信息\"\"\"\n",
    "    inputs = [f\"question: {x['question']} context: {x['context']}\" for x in batch]\n",
    "    processed = tokenizer(\n",
    "        inputs,\n",
    "        max_length=Config.max_source_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": processed.input_ids,\n",
    "        \"attention_mask\": processed.attention_mask,\n",
    "        \"contexts\": [x[\"context\"] for x in batch],\n",
    "        \"questions\": [x[\"question\"] for x in batch],\n",
    "        \"answers\": [x[\"answers\"] for x in batch],\n",
    "        \"ids\": [x[\"id\"] for x in batch]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8420aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, collate_fn=train_collate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=Config.batch_size,collate_fn=valid_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f79279a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "torch.Size([4, 422])\n",
      "--------------------------------------------------\n",
      "attention_mask:\n",
      "torch.Size([4, 422])\n",
      "--------------------------------------------------\n",
      "labels:\n",
      "torch.Size([4, 7])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 假设你已经定义好 train_dataloader\n",
    "batch = next(iter(train_loader))  # train_loader 就是你的 DataLoader 对象\n",
    "\n",
    "# 将张量移动到 CPU，便于查看\n",
    "for key, value in batch.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(value if isinstance(value, list) else value.shape)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dedf614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids 示例:\n",
      "tensor([    7,  3454,  2055, 21293, 15807,    13,     7, 22316,   271,   930,\n",
      "          217,   373,     7, 25395,  7368,  1733,  1550,    13,     7, 22316,\n",
      "          271,  2273,    13, 19227,   864,  1709,  5334, 24841,  1290, 15312,\n",
      "           25,   226,   373,    13, 20829,   373,    22, 17518, 14711, 27436,\n",
      "        11641,  9459,  4988, 20737, 12252,  1334, 25018,  8692, 18732, 24948,\n",
      "           25,   271,  2855,    13, 22316,   864,  2137,  2055, 20560,     7,\n",
      "        20814, 12303, 11979,   908,  8909, 16903,  5334, 24841,  1290, 15312,\n",
      "           25,   480,  1365,   617,    13, 18607,  1365,  2357,   193,     6,\n",
      "          281,     6,  1057,    86, 22316, 12123, 14886,   276,     3,  6212,\n",
      "         6425,    86, 16149,  1641, 22316,   190,   841,     6,  2881,   387,\n",
      "         4446, 20829,  2273,  2218,  2114,  1038,     4,   480,  1365,   239,\n",
      "           13, 18607,   289,    23,    45,   191, 19227,     6,  4976,    86,\n",
      "        22316,   387,  3821, 14654, 23527,     3,  1079, 22316,   382,    19,\n",
      "         2219,   387,  3821,  1332,     3,   486,   410,     9,   730, 22316,\n",
      "          143,  3821,   276,     4,  5082,   268,   487,  1446,   645,  3822,\n",
      "        14886,   276,    13,  4112,  1574, 19227,     6,  4976,    86, 22316,\n",
      "         3821,  1321,     6, 23527,    26,  3502,  1574, 22316,     5,   507,\n",
      "          839,     6, 20006,   410,   382,    26,  3588,   486, 12608,  1227,\n",
      "           19,  2193,  1530,     6, 23879,  1500,     6,   359,  2378,    86,\n",
      "         1110,  3821,   276,    26,  4399,  3189,    19, 22316, 12689,  7351,\n",
      "            6,   660,    86,  5138,    26,  4989,   576,   149,  2273,  1321,\n",
      "         8433, 14466,  3455,    26,  5622,  1574,  6700, 15157,     6,  1303,\n",
      "         3554,  3821,   382,     3,   486,   874, 11628,     9,  1237,    80,\n",
      "          276,     4, 22875,  2273,    13,  4976,     6, 20829,   330,  1134,\n",
      "           13, 19227,     6, 16409,  4976,     6, 14423,   154,     6,   193,\n",
      "        12901,     3,  2020,   154,     6,  2754,   154,     6, 16767,     6,\n",
      "        15097,     6,   281,   140,     6, 22316,     6,   359,   752,   154,\n",
      "            6,  2280,  4976,     4,     7,   330,  1938,   839,   841,  2479,\n",
      "           13,   413,  1134,  4012,    19,  1848,  4012,     3,   354,  1245,\n",
      "          165, 13049,   441,     4,   735,   688, 10608,    13,  4769,  6785,\n",
      "         5912,    13, 19227, 14149,    22,  4639,   132,    25,     1,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n",
      "解码为文本:\n",
      "question: 人力资源管理专业属于什么类 context: 人力资源管理专业学科:管理学 (Management)门类:工商管理类(Mater of Business Administration)专业名称:人力资源管理 (Human Resources Management)业务培养目标:本专业培养具备管理、经济、法律及人力资源管理等方面的知识和能力,能在事业单位及政府部门从事人力资源管理以及教学、科研方面工作的工商管理学科高级专门人才。业务培养要求:本专业学生上要学习管理学、经济学及人力资源管理方面的基本理论和基本知识,受到人力资源管理方法与技巧方面的基本训练,具有分析和解决人力资源管理问题的基本能力。毕业生应获得以下几方面的知识和能力:1.掌握管理学、经济学及人力资源管理的基本理论、基本知识;2.掌握人力资源管理的定性、定量分析方法;3.具有较强的语言与文字表达、人际沟通、组织协调及领导的基本能力;4.熟悉与人力资源管理有关的方针、政策及法规;5.了解本学科理论前沿与发展动态;6.掌握文献检索、资料查询的基本方法,具有一定科学研究和实际工作能力。主干学科:经济学、工商管理主要课程:管理学、微观经济学、宏观经济学、管理信息系统,统计学、会计学、财务管理、市场营销、经济法、人力资源管理、组织行为学、劳动经济学。 主要实践性教学环节:包括课程实习与毕业实习,一般安排10-12周。修业年限:四年授予学位:管理学学士(荣誉生)\n",
      "\n",
      "labels 示例:\n",
      "tensor([    7, 20829,   373,     1,  -100,  -100,  -100])\n",
      "解码为文本:\n",
      "工商管理类\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids 示例:\")\n",
    "print(batch[\"input_ids\"][0])  # 第一个样本的 token id 序列\n",
    "print(\"解码为文本:\")\n",
    "print(tokenizer.decode(batch[\"input_ids\"][0], skip_special_tokens=True))\n",
    "\n",
    "print(\"\\nlabels 示例:\")\n",
    "print(batch[\"labels\"][0])\n",
    "print(\"解码为文本:\")\n",
    "label_ids = batch[\"labels\"][0]\n",
    "# 替换掉 -100（忽略值）为 pad_token_id，再解码\n",
    "label_ids = [id if id != -100 else tokenizer.pad_token_id for id in label_ids]\n",
    "print(tokenizer.decode(label_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f2df3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BleuEvaluator:\n",
    "    def __init__(self):\n",
    "        # BLEU 在遇到 n-gram 零计数时会变为 0，smoothing 可以避免完全为 0 的极端情况，使得短句或稀疏 n-gram 的得分更平滑、更有区分度。\n",
    "        self.smooth = SmoothingFunction().method1\n",
    "        self.weights = {\n",
    "            1: (1, 0, 0, 0),\n",
    "            2: (0.5, 0.5, 0, 0),\n",
    "            3: (1/3, 1/3, 1/3, 0),\n",
    "            4: (0.25, 0.25, 0.25, 0.25)\n",
    "        }\n",
    "\n",
    "    # 这里把整个字符串按 字符（而不是按词）切分成 token 列表，常见于中文处理。\n",
    "    def calc_bleu(self, pred, refs):\n",
    "        pred_tokens = list(pred.strip())\n",
    "        ref_tokens = [list(r.strip()) for r in refs]\n",
    "        return {\n",
    "            f\"BLEU-{n}\": sentence_bleu(\n",
    "                ref_tokens, pred_tokens,\n",
    "                weights=self.weights[n],\n",
    "                smoothing_function=self.smooth\n",
    "            ) for n in range(1, 5)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    # 动态综合得分\n",
    "    def dynamic_score(scores, pred_len):\n",
    "        \"\"\"短回答（如 1–2 字）完全依赖较低阶 n-gram；长回答则更需要高阶 n-gram 来衡量连贯性和词序。\"\"\"\n",
    "        if pred_len <= 2:\n",
    "            return scores[\"BLEU-1\"] * 0.6 + scores[\"BLEU-2\"] * 0.4\n",
    "        elif 3 <= pred_len <= 5:\n",
    "            return scores[\"BLEU-2\"] * 0.5 + scores[\"BLEU-3\"] * 0.3 + scores[\"BLEU-4\"] * 0.2\n",
    "        else:\n",
    "            return scores[\"BLEU-4\"] * 0.7 + scores[\"BLEU-3\"] * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "640c5ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(Config.model_checkpoint).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861431e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "lr_history = []\n",
    "bleu1_history = []\n",
    "bleu2_history = []\n",
    "bleu3_history = []\n",
    "bleu4_history = []\n",
    "dynamic_history = []\n",
    "evaluator = BleuEvaluator()\n",
    "all_bleu = []\n",
    "all_dynamic = []\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_training_steps = len(train_loader) * Config.epochs // Config.accum_steps\n",
    "num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup，可调\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4415ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for step, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss / Config.accum_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (step+1) % Config.accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() *  Config.accum_steps\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + step):>7f}')\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c780022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loader, model):\n",
    "    \n",
    "    model.eval()\n",
    "    for batch in loader:\n",
    "        inputs = batch[\"input_ids\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(\n",
    "                inputs,\n",
    "                max_length=Config.max_target_length,\n",
    "                num_beams=5,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        preds = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "        \n",
    "        for i, (pred, refs) in enumerate(zip(preds, batch[\"answers\"])):\n",
    "            bleu = evaluator.calc_bleu(pred, refs)\n",
    "            all_bleu.append(bleu)\n",
    "            \n",
    "            pred_len = len(list(pred.strip()))\n",
    "            dynamic = BleuEvaluator.dynamic_score(bleu, pred_len)\n",
    "            all_dynamic.append(dynamic)\n",
    "    \n",
    "    avg_bleu = {\n",
    "        f\"BLEU-{n}\": np.mean([b[f\"BLEU-{n}\"] for b in all_bleu]) * 100\n",
    "        for n in range(1, 5)\n",
    "    }\n",
    "    avg_dynamic = np.mean(all_dynamic) * 100\n",
    "    return avg_bleu, avg_dynamic\n",
    "\n",
    "def save_model(epoch, dynamic_score):\n",
    "    save_path = Path(Config.save_dir) / f\"epoch_{epoch}_dynamic_{dynamic_score:.2f}\"\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    print(f\"\\n模型保存至: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ef2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.762119: 100%|██████████| 3630/3630 [08:48<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 验证结果：BLEU-1: 77.47%, BLEU-2: 75.32%, BLEU-3: 68.31%, BLEU-4: 62.08%, 动态得分: 73.72%\n",
      "\n",
      "模型保存至: best_models/epoch_1_dynamic_73.72\n",
      "Epoch 2/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.126257: 100%|██████████| 3630/3630 [08:49<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 验证结果：BLEU-1: 78.59%, BLEU-2: 76.59%, BLEU-3: 69.46%, BLEU-4: 63.22%, 动态得分: 74.95%\n",
      "\n",
      "模型保存至: best_models/epoch_2_dynamic_74.95\n",
      "Epoch 3/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.864148: 100%|██████████| 3630/3630 [08:43<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 验证结果：BLEU-1: 78.58%, BLEU-2: 76.57%, BLEU-3: 69.24%, BLEU-4: 62.91%, 动态得分: 74.84%\n",
      "Epoch 4/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.712567: 100%|██████████| 3630/3630 [08:44<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 验证结果：BLEU-1: 78.63%, BLEU-2: 76.63%, BLEU-3: 69.40%, BLEU-4: 63.14%, 动态得分: 74.91%\n",
      "Epoch 5/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.607310: 100%|██████████| 3630/3630 [08:52<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 验证结果：BLEU-1: 78.33%, BLEU-2: 76.32%, BLEU-3: 69.02%, BLEU-4: 62.68%, 动态得分: 74.55%\n",
      "\n",
      "[完整验证] BLEU-4: 62.38% | 动态得分: 74.31%\n",
      "Epoch 6/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.528563: 100%|██████████| 3630/3630 [08:52<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 验证结果：BLEU-1: 78.05%, BLEU-2: 76.01%, BLEU-3: 68.69%, BLEU-4: 62.29%, 动态得分: 74.20%\n",
      "Epoch 7/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.470695: 100%|██████████| 3630/3630 [09:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 验证结果：BLEU-1: 77.90%, BLEU-2: 75.85%, BLEU-3: 68.54%, BLEU-4: 62.18%, 动态得分: 74.07%\n",
      "Epoch 8/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.425744: 100%|██████████| 3630/3630 [08:57<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 验证结果：BLEU-1: 77.80%, BLEU-2: 75.73%, BLEU-3: 68.45%, BLEU-4: 62.09%, 动态得分: 73.95%\n",
      "Epoch 9/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.389001: 100%|██████████| 3630/3630 [09:03<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 验证结果：BLEU-1: 77.85%, BLEU-2: 75.77%, BLEU-3: 68.50%, BLEU-4: 62.13%, 动态得分: 73.98%\n",
      "Epoch 10/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.357560: 100%|██████████| 3630/3630 [09:07<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 验证结果：BLEU-1: 77.68%, BLEU-2: 75.57%, BLEU-3: 68.29%, BLEU-4: 61.93%, 动态得分: 73.78%\n",
      "\n",
      "[完整验证] BLEU-4: 61.76% | 动态得分: 73.60%\n",
      "Epoch 11/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.330642: 100%|██████████| 3630/3630 [09:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 验证结果：BLEU-1: 77.44%, BLEU-2: 75.29%, BLEU-3: 68.00%, BLEU-4: 61.64%, 动态得分: 73.50%\n",
      "Epoch 12/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.307831: 100%|██████████| 3630/3630 [08:59<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 验证结果：BLEU-1: 77.42%, BLEU-2: 75.26%, BLEU-3: 68.03%, BLEU-4: 61.67%, 动态得分: 73.47%\n",
      "Epoch 13/30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.291099:  85%|████████▍ | 3071/3630 [07:38<01:23,  6.73it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Config\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mConfig\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     chunk_bleu, dynamic_score \u001b[38;5;241m=\u001b[39m validate(valid_loader, model)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 拆分各 BLEU 分数\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, optimizer, lr_scheduler, epoch, total_loss)\u001b[0m\n\u001b[1;32m      9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch_data)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m/\u001b[39m Config\u001b[38;5;241m.\u001b[39maccum_steps\n\u001b[0;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m Config\u001b[38;5;241m.\u001b[39maccum_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_loss = 0.\n",
    "best_dynamic = 0.\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    print(f\"Epoch {epoch+1}/{Config.epochs}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_loader, model, optimizer, scheduler, epoch+1, total_loss)\n",
    "    chunk_bleu, dynamic_score = validate(valid_loader, model)\n",
    "\n",
    "# 拆分各 BLEU 分数\n",
    "    bleu1_history.append(chunk_bleu[\"BLEU-1\"])\n",
    "    bleu2_history.append(chunk_bleu[\"BLEU-2\"])\n",
    "    bleu3_history.append(chunk_bleu[\"BLEU-3\"])\n",
    "    bleu4_history.append(chunk_bleu[\"BLEU-4\"])\n",
    "    dynamic_history.append(dynamic_score)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} 验证结果：BLEU-1: {chunk_bleu['BLEU-1']:.2f}%, \"\n",
    "      f\"BLEU-2: {chunk_bleu['BLEU-2']:.2f}%, \"\n",
    "      f\"BLEU-3: {chunk_bleu['BLEU-3']:.2f}%, \"\n",
    "      f\"BLEU-4: {chunk_bleu['BLEU-4']:.2f}%, \"\n",
    "      f\"动态得分: {dynamic_score:.2f}%\")\n",
    "\n",
    "    if dynamic_score > best_dynamic:\n",
    "        best_dynamic = dynamic_score\n",
    "        save_model(epoch+1, dynamic_score)\n",
    "    \n",
    "    if (epoch+1) % 5 == 0 or epoch == Config.epochs-1:\n",
    "        full_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=Config.batch_size,\n",
    "            collate_fn=valid_collate\n",
    "        )\n",
    "\n",
    "        full_bleu , full_avg_dynamic = validate(full_loader, model)\n",
    "        print(f\"\\n[完整验证] BLEU-4: {full_bleu['BLEU-4']:.2f}% | 动态得分: {full_avg_dynamic:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082bf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
